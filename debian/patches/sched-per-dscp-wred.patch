This patch will add support for per Q dscp WRED.  The requirement is
to support several WRED configurations on a Q so when several types
of control traffic are enqueued to the same Q it's possible to give
a lower drop probability to specific types.

To provide the support several WRED configurations can be stored in
a rte_sched_queue_extra structure, when rte_sched_pipe_config_v2 is
called each one is passed into rte_red_config_init to initialize the
runtime data.

Signed-off-by: Alan Robertson <alan.robertson@intl.att.com>
---
--- a/lib/librte_sched/rte_red.c
+++ b/lib/librte_sched/rte_red.c
@@ -3,7 +3,7 @@
  */
 
 #include <math.h>
-#include "rte_red.h"
+#include "rte_sched.h"
 #include <rte_random.h>
 #include <rte_common.h>
 
@@ -169,3 +169,66 @@ rte_red_reset_scaling(void)
 	rte_red_scaling = RTE_RED_SCALING_DEFAULT;
 	rte_red_max_threshold = RTE_RED_DEFAULT_QUEUE_LENGTH - 1;
 }
+
+struct rte_red_pipe_params *
+rte_red_alloc_q_params(struct rte_sched_pipe_params *pipe, unsigned int qindex)
+{
+	struct rte_red_pipe_params *wred_params;
+
+	wred_params = malloc(sizeof(struct rte_red_pipe_params));
+	if (!wred_params) {
+		RTE_LOG(ERR, SCHED, "qred_info calloc failed\n");
+		return NULL;
+	}
+	memset(wred_params, 0, sizeof(struct rte_red_pipe_params));
+	wred_params->qindex = qindex;
+	SLIST_INSERT_HEAD(&pipe->qred_head, wred_params, list);
+	return wred_params;
+}
+
+struct rte_red_pipe_params *
+rte_red_find_q_params(struct rte_sched_pipe_params *pipe, unsigned int qindex)
+{
+	struct rte_red_pipe_params *wred_params = NULL;
+
+	SLIST_FOREACH(wred_params, &pipe->qred_head, list) {
+		if (wred_params->qindex == qindex)
+			break;
+	}
+	return wred_params;
+}
+
+int
+rte_red_init_q_params(struct rte_red_q_params *wred_params,
+                      unsigned qmax, unsigned qmin, unsigned prob,
+                      uint64_t dscp_set)
+{
+	int wred_index;
+
+	if (!wred_params || wred_params->num_maps > RTE_MAX_DSCP_MAPS) {
+		RTE_LOG(ERR, SCHED, "Invalid DSCP map init params\n");
+		return -1;
+	}
+
+	wred_index = wred_params->num_maps++;
+	wred_params->qparams[wred_index].max_th = qmax;
+	wred_params->qparams[wred_index].min_th = qmin;
+	wred_params->qparams[wred_index].maxp_inv = prob;
+	wred_params->dscp_set[wred_index] = dscp_set;
+	return 0;
+}
+
+void
+rte_red_free_q_params(struct rte_sched_pipe_params *pipe, int i)
+{
+	struct rte_red_pipe_params *wred_params;
+
+	while ((wred_params = SLIST_FIRST(&pipe->qred_head)) != NULL) {
+		SLIST_REMOVE_HEAD(&pipe->qred_head, list);
+		RTE_LOG(DEBUG, SCHED,
+			"Freeing Q RED params qindex %u profile "
+			"%u pipe %p wred_params %p\n",
+			wred_params->qindex, i, pipe, wred_params);
+		free(wred_params);
+	}
+}
--- a/lib/librte_sched/rte_red.h
+++ b/lib/librte_sched/rte_red.h
@@ -70,6 +70,30 @@ struct rte_red_config {
 };
 
 /**
+ * Per queue red parameters
+ */
+#define RTE_NUM_DSCP_MAPS	4
+#define RTE_MAX_DSCP_MAPS	(RTE_NUM_DSCP_MAPS - 1)
+
+struct rte_red_q_params {
+	uint64_t	dscp_set[RTE_NUM_DSCP_MAPS];
+	struct rte_red_params qparams[RTE_NUM_DSCP_MAPS];
+	uint8_t		num_maps;
+};
+
+struct rte_red_pipe_params {
+	SLIST_ENTRY(rte_red_pipe_params) list;
+	struct rte_red_q_params red_q_params;
+	uint8_t		qindex;
+};
+
+struct rte_red_q_config {
+	uint64_t	dscp_set[RTE_NUM_DSCP_MAPS];
+	struct rte_red_config qcfg[RTE_NUM_DSCP_MAPS];
+	uint8_t		num_maps;
+};
+
+/**
  * RED run-time data
  */
 struct rte_red {
--- a/lib/librte_sched/rte_sched.c
+++ b/lib/librte_sched/rte_sched.c
@@ -5,6 +5,10 @@
 #include <stdio.h>
 #include <string.h>
 
+#include <netinet/in.h>
+#include <netinet/ip.h>
+#include <netinet/ip6.h>
+
 #include <rte_common.h>
 #include <rte_log.h>
 #include <rte_memory.h>
@@ -128,6 +132,7 @@ struct rte_sched_queue_extra {
 	struct rte_sched_queue_stats stats;
 #ifdef RTE_SCHED_RED
 	struct rte_red red;
+	struct rte_red_q_config qred;
 #endif
 };
 
@@ -144,22 +149,6 @@ enum token_state {
 	TOKENS_AVAIL
 };
 
-/*
- * Path through the scheduler hierarchy used by the scheduler enqueue
- * operation to identify the destination queue for the current
- * packet. Stored in the field pkt.hash.sched of struct rte_mbuf of
- * each packet, typically written by the classification stage and read
- * by scheduler enqueue.
- */
-struct rte_sched_port_hierarchy {
-	uint16_t queue:RTE_SCHED_WRR_BITS;         /**< Queue ID */
-	uint16_t traffic_class:RTE_SCHED_TC_BITS;  /**< Traffic class ID */
-	uint16_t color:2;                          /**< Color */
-	uint32_t unused:16 - (2 + RTE_SCHED_WRR_BITS + RTE_SCHED_TC_BITS);
-	uint16_t subport;                          /**< Subport ID */
-	uint32_t pipe;		                   /**< Pipe ID */
-};
-
 struct rte_sched_grinder {
 	/* Pipe cache */
 	uint16_t pcache_qmask[RTE_SCHED_GRINDER_PCACHE_SIZE];
@@ -1139,6 +1128,19 @@ rte_sched_subport_config_v2(struct rte_s
 					       qsize, red_params);
 }
 
+static inline uint32_t
+rte_sched_port_qindex(struct rte_sched_port *port, uint32_t subport,
+		      uint32_t pipe, uint32_t traffic_class, uint32_t queue)
+{
+	uint32_t result;
+
+	result = subport * port->n_pipes_per_subport + pipe;
+	result = result * RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE + traffic_class;
+	result = result * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + queue;
+
+	return result;
+}
+
 int
 rte_sched_pipe_config(struct rte_sched_port *port,
 	uint32_t subport_id,
@@ -1291,6 +1293,55 @@ rte_sched_port_pipe_profile_add(struct r
 	return 0;
 }
 
+int
+rte_sched_pipe_config_v2(struct rte_sched_port *port,
+	uint32_t subport_id,
+	uint32_t pipe_id,
+	int32_t pipe_profile,
+	struct rte_sched_port_params *port_params)
+{
+	int ret;
+	struct rte_sched_pipe_params *p_profs;
+	struct rte_red_pipe_params *wred_params;
+
+	ret = rte_sched_pipe_config(port, subport_id, pipe_id, pipe_profile);
+	if (ret != 0)
+		return ret;
+
+	p_profs = port_params->pipe_profiles + pipe_profile;
+
+	SLIST_FOREACH(wred_params, &p_profs->qred_head, list) {
+		int i;
+		uint32_t qindex = (wred_params->qindex >> RTE_SCHED_TC_BITS) &
+				RTE_SCHED_WRR_MASK;
+		uint32_t tc = wred_params->qindex & RTE_SCHED_TC_MASK;
+		struct rte_sched_queue_extra *qxtra;
+
+		qindex = rte_sched_port_qindex(port, subport_id, pipe_id,
+					       tc, qindex);
+		qxtra = port->queue_extra + qindex;
+
+		for (i = 0; i < wred_params->red_q_params.num_maps; i++) {
+			rte_red_rt_data_init(&qxtra->red);
+			if (rte_red_config_init(&qxtra->qred.qcfg[i],
+				wred_params->red_q_params.qparams[i].wq_log2,
+				wred_params->red_q_params.qparams[i].min_th,
+				wred_params->red_q_params.qparams[i].max_th,
+				wred_params->red_q_params.qparams[i].maxp_inv))
+				return -1;
+			qxtra->qred.dscp_set[i] =
+				wred_params->red_q_params.dscp_set[i];
+		}
+		qxtra->qred.num_maps = wred_params->red_q_params.num_maps;
+
+		RTE_LOG(DEBUG, SCHED,
+			"Setup per Q wred sub %u pip %u qind %u maps %u\n",
+			subport_id, pipe_id, qindex, qxtra->qred.num_maps);
+	}
+
+	return ret;
+}
+
 void
 rte_sched_port_pkt_write(struct rte_mbuf *pkt,
 			 uint32_t subport, uint32_t pipe, uint32_t traffic_class,
@@ -1309,6 +1360,21 @@ rte_sched_port_pkt_write(struct rte_mbuf
 }
 
 void
+rte_sched_port_pkt_write_v2(struct rte_mbuf *pkt, uint32_t subport,
+			    uint32_t pipe, uint32_t traffic_class,
+			    uint32_t queue, enum rte_color color,
+			    uint16_t dscp)
+{
+	struct rte_sched_port_hierarchy *sched
+		= (struct rte_sched_port_hierarchy *) &pkt->hash.sched;
+
+	rte_sched_port_pkt_write(pkt, subport, pipe, traffic_class,
+				 queue, color);
+
+	sched->dscp = dscp;
+}
+
+void
 rte_sched_port_pkt_read_tree_path(const struct rte_mbuf *pkt,
 				  uint32_t *subport, uint32_t *pipe,
 				  uint32_t *traffic_class, uint32_t *queue)
@@ -1385,18 +1451,6 @@ rte_sched_queue_read_stats(struct rte_sc
 	return 0;
 }
 
-static inline uint32_t
-rte_sched_port_qindex(struct rte_sched_port *port, uint32_t subport, uint32_t pipe, uint32_t traffic_class, uint32_t queue)
-{
-	uint32_t result;
-
-	result = subport * port->n_pipes_per_subport + pipe;
-	result = result * RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE + traffic_class;
-	result = result * RTE_SCHED_QUEUES_PER_TRAFFIC_CLASS + queue;
-
-	return result;
-}
-
 #ifdef RTE_SCHED_DEBUG
 
 static inline int
@@ -1483,7 +1537,8 @@ rte_sched_port_update_queue_stats_on_dro
 #ifdef RTE_SCHED_RED
 
 static inline int
-rte_sched_port_red_drop(struct rte_sched_port *port, struct rte_mbuf *pkt, uint32_t qindex, uint16_t qlen)
+rte_sched_port_red_drop(struct rte_sched_port *port, struct rte_mbuf *pkt,
+			uint32_t qindex, uint16_t qlen)
 {
 	struct rte_sched_subport *subport = port->subport +
 		(qindex / rte_sched_port_queues_per_subport(port));
@@ -1497,13 +1552,33 @@ rte_sched_port_red_drop(struct rte_sched
 	color = rte_sched_port_pkt_read_color(pkt);
 	red_cfg = &subport->red_config[tc_index][color];
 
-	if ((red_cfg->min_th | red_cfg->max_th) == 0)
+	qe = port->queue_extra + qindex;
+
+	if ((red_cfg->min_th | red_cfg->max_th) == 0 &&
+	    !qe->qred.num_maps)
 		return 0;
 
-	qe = port->queue_extra + qindex;
 	red = &qe->red;
 
-	return rte_red_enqueue(red_cfg, red, qlen, port->time);
+	if (qe->qred.num_maps) {
+		int i;
+		struct rte_sched_port_hierarchy *sched =
+			(struct rte_sched_port_hierarchy *) &pkt->hash.sched;
+		uint64_t dscp_mask;
+		dscp_mask = (sched->dscp < MAX_DSCP) ? (1lu << sched->dscp) : 0;
+		for (i = 0; i < qe->qred.num_maps; i++) {
+			if (dscp_mask & qe->qred.dscp_set[i]) {
+				red_cfg = &qe->qred.qcfg[i];
+				break;
+			}
+		}
+
+		/* If we haven't found a dscp match then force a drop */
+		if (i >= qe->qred.num_maps)
+			return 1;
+	}
+
+	return rte_red_enqueue(red_cfg, red, qlen, port->time_cpu_bytes);
 }
 
 static inline void
@@ -1512,7 +1587,7 @@ rte_sched_port_set_queue_empty_timestamp
 	struct rte_sched_queue_extra *qe = port->queue_extra + qindex;
 	struct rte_red *red = &qe->red;
 
-	rte_red_mark_queue_empty(red, port->time);
+	rte_red_mark_queue_empty(red, port->time_cpu_bytes);
 }
 
 #else
--- a/lib/librte_sched/rte_sched.h
+++ b/lib/librte_sched/rte_sched.h
@@ -116,6 +116,11 @@ extern "C" {
 #define RTE_SCHED_FRAME_OVERHEAD_DEFAULT      24
 #endif
 
+#define PCP_BITS	3
+#define MAX_PCP		(1 << PCP_BITS)
+#define DSCP_BITS	6
+#define MAX_DSCP	(1 << DSCP_BITS)
+
 /*
  * Subport configuration parameters. The period and credits_per_period
  * parameters are measured in bytes, with one byte meaning the time
@@ -182,6 +187,7 @@ struct rte_sched_pipe_params {
 
 	/* Pipe queues */
 	uint8_t  wrr_weights[RTE_SCHED_QUEUES_PER_PIPE]; /**< WRR weights */
+	SLIST_HEAD(qred_head, rte_red_pipe_params) qred_head;
 };
 
 /** Queue statistics */
@@ -227,6 +233,23 @@ struct rte_sched_port_params {
 };
 
 /*
+ * Path through the scheduler hierarchy used by the scheduler enqueue
+ * operation to identify the destination queue for the current
+ * packet. Stored in the field pkt.hash.sched of struct rte_mbuf of
+ * each packet, typically written by the classification stage and read
+ * by scheduler enqueue.
+ */
+struct rte_sched_port_hierarchy {
+	uint16_t queue:RTE_SCHED_WRR_BITS;	  /**< Queue ID */
+	uint16_t traffic_class:RTE_SCHED_TC_BITS; /**< Traffic class ID */
+	uint16_t color:2;			  /**< Color */
+	uint16_t dscp:7;			  /**< dscp */
+	uint32_t unused:9 - (2 + RTE_SCHED_WRR_BITS + RTE_SCHED_TC_BITS);
+	uint16_t subport;			  /**< Subport ID */
+	uint32_t pipe;				  /**< Pipe ID */
+};
+
+/*
  * Configuration
  *
  ***/
@@ -346,6 +369,29 @@ rte_sched_pipe_config(struct rte_sched_p
 	int32_t pipe_profile);
 
 /**
+ * Hierarchical scheduler pipe configuration
+ *
+ * @param port
+ *   Handle to port scheduler instance
+ * @param subport_id
+ *   Subport ID
+ * @param pipe_id
+ *   Pipe ID within subport
+ * @param pipe_profile
+ *   ID of port-level pre-configured pipe profile
+ * @param port_params
+ *   A pointer to the user provided port parameters
+ * @return
+ *   0 upon success, error code otherwise
+ */
+int
+rte_sched_pipe_config_v2(struct rte_sched_port *port,
+	uint32_t subport_id,
+	uint32_t pipe_id,
+	int32_t pipe_profile,
+	struct rte_sched_port_params *port_params);
+
+/**
  * Hierarchical scheduler memory footprint size per port
  *
  * @param params
@@ -442,6 +488,31 @@ rte_sched_port_pkt_write(struct rte_mbuf
 			 uint32_t queue, enum rte_color color);
 
 /**
+ * Scheduler hierarchy path write to packet descriptor. Typically
+ * called by the packet classification stage.
+ *
+ * @param pkt
+ *   Packet descriptor handle
+ * @param subport
+ *   Subport ID
+ * @param pipe
+ *   Pipe ID within subport
+ * @param traffic_class
+ *   Traffic class ID within pipe (0 .. 3)
+ * @param queue
+ *   Queue ID within pipe traffic class (0 .. 3)
+ * @param color
+ *   Packet color set
+ * @param dscp
+ *   A mask of the dscp value
+ */
+void
+rte_sched_port_pkt_write_v2(struct rte_mbuf *pkt, uint32_t subport,
+			    uint32_t pipe, uint32_t traffic_class,
+			    uint32_t queue, enum rte_color color,
+			    uint16_t dscp);
+
+/**
  * Scheduler hierarchy path read from packet descriptor (struct
  * rte_mbuf). Typically called as part of the hierarchical scheduler
  * enqueue operation. The subport, pipe, traffic class and queue
@@ -508,6 +579,82 @@ rte_sched_port_enqueue(struct rte_sched_
 int
 rte_sched_port_dequeue(struct rte_sched_port *port, struct rte_mbuf **pkts, uint32_t n_pkts);
 
+/**
+ * Add a wred parameter configuration to the pipe structure.
+ *
+ * @param pipe
+ *   A pointer to the profile parameters for that pipe
+ * @param wred_params
+ *   A pointer to the parameters
+ * @return
+ *   void
+ */
+void rte_red_add_q_params(struct rte_sched_pipe_params *pipe,
+			  struct rte_red_pipe_params *wred_params);
+
+/**
+ * Allocate and add a wred structure to a pipe structure
+ *
+ * @param pipe
+ *   A pointer to the pipe profile we're adding the structure to.
+ * @param qindex
+ *   The queue index identifier.
+ * @return
+ *   A pointer to the new wred structure.
+ */
+struct rte_red_pipe_params *
+rte_red_alloc_q_params(struct rte_sched_pipe_params *pipe,
+		       unsigned int qindex);
+
+/**
+ * Find a wred parameter structure for a pipe profile using
+ * the queue index.
+ *
+ * @param pipe
+ *   A pointer to the pipe profile.
+ * @param qindex
+ *   The queue index to match.
+ * @return
+ *   A pointer to the wred structure or NULL.
+ */
+struct rte_red_pipe_params *
+rte_red_find_q_params(struct rte_sched_pipe_params *pipe,
+		      unsigned int qindex);
+
+/**
+ * Initialize the wred structure with the parameters.
+ *
+ * @param wred_params
+ *   A pointer to the structure to be initialized.
+ * @param qmax
+ *   The maximum wred threshold.
+ * @param qmin
+ *   The minimum wred threshold.
+ * @param prob
+ *   The probability of dropping the packet.
+ * @param dscp_set
+ *   A 64 bit mask with the DSCP values we're using wred with
+ *   set in the mask.
+ * @return
+ *   0 if successful, -1 if the number of supported maps
+ *   is exceeded.
+ */
+int
+rte_red_init_q_params(struct rte_red_q_params *wred_params,
+		      unsigned qmax, unsigned qmin, unsigned prob,
+		      uint64_t dscp_set);
+
+/**
+ * Free any wred structures associated with this pipe profile.
+ *
+ * @param pipe
+ *   A pointer to the pipe profile structure.
+ * @return
+ *   void
+ */
+void
+rte_red_free_q_params(struct rte_sched_pipe_params *pipe, int i);
+
 #ifdef __cplusplus
 }
 #endif
--- a/lib/librte_sched/rte_sched_version.map
+++ b/lib/librte_sched/rte_sched_version.map
@@ -2,7 +2,11 @@ DPDK_20.0 {
 	global:
 
 	rte_approx;
+	rte_red_alloc_q_params;
 	rte_red_config_init;
+	rte_red_find_q_params;
+	rte_red_free_q_params;
+	rte_red_init_q_params;
 	rte_red_log2_1_minus_Wq;
 	rte_red_max_threshold;
 	rte_red_pow2_frac_inv;
@@ -12,6 +16,7 @@ DPDK_20.0 {
 	rte_red_scaling;
 	rte_red_set_scaling;
 	rte_sched_pipe_config;
+	rte_sched_pipe_config_v2;
 	rte_sched_port_config;
 	rte_sched_port_config_v2;
 	rte_sched_port_dequeue;
@@ -22,6 +27,7 @@ DPDK_20.0 {
 	rte_sched_port_pkt_read_color;
 	rte_sched_port_pkt_read_tree_path;
 	rte_sched_port_pkt_write;
+	rte_sched_port_pkt_write_v2;
 	rte_sched_queue_read_stats;
 	rte_sched_subport_config;
 	rte_sched_subport_config_v2;
