From fe3ea6322c168233da914b2b4ea21b15e13b725f Mon Sep 17 00:00:00 2001
From: Alan Robertson <alan.robertson@intl.att.com>
Date: Fri, 9 Feb 2018 10:04:25 +0000
Subject: [PATCH] Improve the shaper accuracy for large packets

There were 2 issues, the first was time could be lost whilst updating
the traffic-class period, the second was a frame could be delayed if
not enough tokens were available for the full frame.  By allowing the
shaper to borrow credit from the next period the throughput is improved.

Signed-off-by: Alan Robertson <alan.robertson@intl.att.com>
---
--- a/lib/librte_sched/rte_sched.c
+++ b/lib/librte_sched/rte_sched.c
@@ -57,7 +57,7 @@ struct rte_sched_subport {
 	/* Traffic classes (TCs) */
 	uint64_t tc_time; /* time of next update */
 	uint32_t tc_credits_per_period[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
-	uint32_t tc_credits[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
+	int32_t tc_credits[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
 	uint16_t qsize[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
 	uint32_t tc_period;
 
@@ -108,7 +108,7 @@ struct rte_sched_pipe {
 
 	/* Traffic classes (TCs) */
 	uint64_t tc_time; /* time of next update */
-	uint32_t tc_credits[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
+	int32_t tc_credits[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
 
 	/* Weighted Round Robin (WRR) */
 	uint32_t wrr_tokens[RTE_SCHED_QUEUES_PER_PIPE];
@@ -138,6 +138,12 @@ enum grinder_state {
 	e_GRINDER_READ_MBUF
 };
 
+enum token_state {
+	TOKENS_UNDEFINED = 0,
+	TOKENS_USED,
+	TOKENS_AVAIL
+};
+
 /*
  * Path through the scheduler hierarchy used by the scheduler enqueue
  * operation to identify the destination queue for the current
@@ -1794,35 +1800,61 @@ grinder_credits_update(struct rte_sched_
 	struct rte_sched_pipe_profile *params = grinder->pipe_params;
 	uint64_t n_periods;
 	uint32_t tc;
+	uint64_t lapsed;
 
 	/* Subport TB */
-	n_periods = (port->time - subport->tb_time) / subport->tb_period;
+	n_periods = (port->time_cpu_bytes - subport->tb_time) /
+				subport->tb_period;
 	subport->tb_credits += n_periods * subport->tb_credits_per_period;
 	subport->tb_credits = rte_sched_min_val_2_u32(subport->tb_credits, subport->tb_size);
 	subport->tb_time += n_periods * subport->tb_period;
 
 	/* Pipe TB */
-	n_periods = (port->time - pipe->tb_time) / params->tb_period;
+	n_periods = (port->time_cpu_bytes - pipe->tb_time) / params->tb_period;
 	pipe->tb_credits += n_periods * params->tb_credits_per_period;
 	pipe->tb_credits = rte_sched_min_val_2_u32(pipe->tb_credits, params->tb_size);
 	pipe->tb_time += n_periods * params->tb_period;
 
 	/* Subport TCs */
-	if (unlikely(port->time >= subport->tc_time)) {
+	if (unlikely(port->time_cpu_bytes >= subport->tc_time)) {
 		for (tc = 0; tc < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; tc++) {
-			subport->tc_credits[tc] =
-				subport->tc_credits_per_period[tc];
+			if (subport->tc_credits[tc] < 0)
+				subport->tc_credits[tc] +=
+					subport->tc_credits_per_period[tc];
+			else
+				subport->tc_credits[tc] =
+					subport->tc_credits_per_period[tc];
 		}
-		subport->tc_time = port->time + subport->tc_period;
+		/* If we've run into the next period only update the clock to
+		 * the time + tc_period so we'll replenish the tc tokens early
+		 * in the next tc_period to compensate.
+		 */
+		lapsed = port->time_cpu_bytes - subport->tc_time;
+		if (lapsed < subport->tc_period)
+			subport->tc_time += subport->tc_period;
+		else
+			subport->tc_time = port->time + subport->tc_period;
 	}
 
 	/* Pipe TCs */
-	if (unlikely(port->time >= pipe->tc_time)) {
+	if (unlikely(port->time_cpu_bytes >= pipe->tc_time)) {
 		for (tc = 0; tc < RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE; tc++) {
-			pipe->tc_credits[tc] =
-				params->tc_credits_per_period[tc];
+			if (pipe->tc_credits[tc] < 0)
+				pipe->tc_credits[tc] +=
+					params->tc_credits_per_period[tc];
+			else
+				pipe->tc_credits[tc] =
+					params->tc_credits_per_period[tc];
 		}
-		pipe->tc_time = port->time + params->tc_period;
+		/* If we've run into the next period only update the clock to
+		 * the time + tc_period so we'll replenish the tc tokens early
+		 * in the next tc_period to compensate.
+		 */
+		lapsed = port->time_cpu_bytes - pipe->tc_time;
+		if (lapsed < params->tc_period)
+			pipe->tc_time += params->tc_period;
+		else
+			pipe->tc_time = port->time + params->tc_period;
 	}
 }
 
@@ -1933,19 +1965,19 @@ grinder_credits_check(struct rte_sched_p
 	uint32_t tc_index = grinder->tc_index;
 	int32_t pkt_len = pkt->pkt_len + port->frame_overhead;
 	uint32_t subport_tb_credits = subport->tb_credits;
-	uint32_t subport_tc_credits = subport->tc_credits[tc_index];
+	int32_t subport_tc_credits = subport->tc_credits[tc_index];
 	uint32_t pipe_tb_credits = pipe->tb_credits;
-	uint32_t pipe_tc_credits = pipe->tc_credits[tc_index];
+	int32_t pipe_tc_credits = pipe->tc_credits[tc_index];
 	int enough_credits;
 
 	if (pkt_len < 0)
 		pkt_len = 0;
 
 	/* Check queue credits */
-	enough_credits = (pkt_len <= subport_tb_credits) &&
-		(pkt_len <= subport_tc_credits) &&
-		(pkt_len <= pipe_tb_credits) &&
-		(pkt_len <= pipe_tc_credits);
+	enough_credits = (pkt_len <= (int32_t)subport_tb_credits) &&
+		(subport_tc_credits > 0) &&
+		(pkt_len <= (int32_t)pipe_tb_credits) &&
+		(pipe_tc_credits > 0);
 
 	if (!enough_credits)
 		return 0;
@@ -1953,8 +1985,8 @@ grinder_credits_check(struct rte_sched_p
 	/* Update port credits */
 	subport->tb_credits -= pkt_len;
 	subport->tc_credits[tc_index] -= pkt_len;
-	pipe->tb_credits -= pkt_len;
 	pipe->tc_credits[tc_index] -= pkt_len;
+	pipe->tb_credits -= pkt_len;
 
 	return 1;
 }
@@ -2006,15 +2038,20 @@ grinder_credits_check(struct rte_sched_p
 
 
 static inline int
-grinder_schedule(struct rte_sched_port *port, uint32_t pos)
+grinder_schedule(struct rte_sched_port *port, uint32_t pos,
+		 enum token_state *token_state)
 {
 	struct rte_sched_grinder *grinder = port->grinder + pos;
 	struct rte_sched_queue *queue = grinder->queue[grinder->qpos];
 	struct rte_mbuf *pkt = grinder->pkt;
 	int32_t pkt_len = pkt->pkt_len + port->frame_overhead;
 
-	if (!grinder_credits_check(port, pos))
+	if (!grinder_credits_check(port, pos)) {
+		*token_state = TOKENS_USED;
 		return 0;
+	}
+
+	*token_state = TOKENS_AVAIL;
 
 	if (pkt_len < 0)
 		pkt_len = 0;
@@ -2357,7 +2394,8 @@ grinder_prefetch_mbuf(struct rte_sched_p
 }
 
 static inline uint32_t
-grinder_handle(struct rte_sched_port *port, uint32_t pos)
+grinder_handle(struct rte_sched_port *port, uint32_t pos,
+	       enum token_state *token_state)
 {
 	struct rte_sched_grinder *grinder = port->grinder + pos;
 
@@ -2399,7 +2437,7 @@ grinder_handle(struct rte_sched_port *po
 	{
 		uint32_t result = 0;
 
-		result = grinder_schedule(port, pos);
+		result = grinder_schedule(port, pos, token_state);
 
 		/* Look for next packet within the same TC */
 		if (result && grinder->qmask) {
@@ -2490,7 +2528,10 @@ rte_sched_port_exceptions(struct rte_sch
 int
 rte_sched_port_dequeue(struct rte_sched_port *port, struct rte_mbuf **pkts, uint32_t n_pkts)
 {
-	uint32_t i, count;
+	uint32_t i, count, j;
+	enum token_state token_state;
+	uint32_t npipes = port->n_subports_per_port *
+				port->n_pipes_per_subport;
 
 	port->pkts_out = pkts;
 	port->n_pkts_out = 0;
@@ -2498,12 +2539,27 @@ rte_sched_port_dequeue(struct rte_sched_
 	rte_sched_port_time_resync(port);
 
 	/* Take each queue in the grinder one step further */
-	for (i = 0, count = 0; ; i++)  {
-		count += grinder_handle(port, i & (RTE_SCHED_PORT_N_GRINDERS - 1));
+	for (i = 0, count = 0, j = 0; ; i++)  {
+		token_state = TOKENS_UNDEFINED;
+		count += grinder_handle(port, i & (RTE_SCHED_PORT_N_GRINDERS - 1),
+					&token_state);
 		if ((count == n_pkts) ||
 		    rte_sched_port_exceptions(port, i >= RTE_SCHED_PORT_N_GRINDERS)) {
 			break;
 		}
+		/* We need to look at all pipes */
+		if ((i+1) < npipes)
+			continue;
+		/*
+		 * If we've been through all the pipes and none have any
+		 * tokens leave the loop.
+		 */
+		if (token_state == TOKENS_USED) {
+			if (j++ >= npipes)
+				break;
+		} else if (token_state == TOKENS_AVAIL) {
+			j = 0;
+		}
 	}
 
 	return count;
--- a/lib/librte_sched/rte_sched.h
+++ b/lib/librte_sched/rte_sched.h
@@ -127,14 +127,14 @@ extern "C" {
  */
 struct rte_sched_subport_params {
 	/* Subport token bucket */
-	uint32_t tb_rate;                /**< Rate (measured in bytes per second) */
-	uint32_t tb_size;                /**< Size (measured in credits) */
-
+	uint64_t tb_rate;                /**< Rate (measured in bytes per second) */
 	/* Subport traffic classes */
-	uint32_t tc_rate[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
+	uint64_t tc_rate[RTE_SCHED_TRAFFIC_CLASSES_PER_PIPE];
 	/**< Traffic class rates (measured in bytes per second) */
 	uint32_t tc_period;
 	/**< Enforcement period for rates (measured in milliseconds) */
+	/* Subport token bucket burst size */
+	uint32_t tb_size;                /**< Size (measured in credits) */
 };
 
 /** Subport statistics */
